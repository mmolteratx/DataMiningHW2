{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7b2b4c51cdc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#from sklearn.cross_validation import train_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ticks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Set2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlated columns\n",
    "# Suppose p = 5, n = 500 -- a good ratio\n",
    "p = 5; n = 500\n",
    "X = np.random.randn(n,p)\n",
    "c = np.dot(X[:,0:p-1],[2,3,-1,0.5]) + np.random.randn(1,n)/1000;\n",
    "# c is a column that is approximately a linear combination of\n",
    "# columns 1, 2, 3 and 4. We set the 5th column of X equal to c\n",
    "X[:,p-1] = c\n",
    "beta = np.array([1,1,1,1,0])\n",
    "sigma = 0.3333\n",
    "y = np.dot(X,beta) + sigma*np.random.randn(n)\n",
    "# Now let's also generate a test data set\n",
    "n1 = 500 # number of testing points\n",
    "X_test = np.random.randn(n1,p)\n",
    "# In the test set, there's more noise in the 5th column\n",
    "c_test = np.dot(X_test[:,0:p-1],[2,3,-1,0.5]) + np.random.randn(1,n1)/50;\n",
    "X_test[:,p-1] = c_test\n",
    "y_test = np.dot(X_test,beta) + sigma*np.random.randn(n1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the test error of the “zero-variance” solution, namely, the all-zeros solution? (Note that due to the random numbers generated, your solution will not be identical every time you run it, or if you compare with another homework group. You may consider fixing the random seed).\n",
    "\n",
    "See below. For our run, 45.229 is the approximate test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.228743961847705"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Beta_hat_R using all zeros solution\n",
    "beta_hat_R = [0, 0, 0, 0, 0]\n",
    "\n",
    "# Finally, let's compute the test error for the ridge regression solution.\n",
    "np.linalg.norm(np.dot(X_test,beta_hat_R) - y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The least-squares solution does not seem to do too well, because it has so much variance. Still, it is unbiased. Show this empirically: generate many copies of the data, and for each one, obtain the least-squares solution. Average these, to show that while each run produces a beta hat that is very different, their average begins to look more and more like the true beta.\n",
    "\n",
    "See below for 10000x run, showing recovered beta of [0.9983274799279912, 0.9977620841953185, 1.000794816886055, 0.9996759282628082, 0.0007649002087681994] in our test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9983274799279912, 0.9977620841953185, 1.000794816886055, 0.9996759282628082, 0.0007649002087681994]\n"
     ]
    }
   ],
   "source": [
    "beta_hat_avg = [0, 0, 0, 0, 0]\n",
    "\n",
    "for i in range(0, 10000):\n",
    "    # Now let's also generate a test data set\n",
    "    n1 = 500 # number of testing points\n",
    "    X_test = np.random.randn(n1,p)\n",
    "    # In the test set, there's more noise in the 5th column\n",
    "    c_test = np.dot(X_test[:,0:p-1],[2,3,-1,0.5]) + np.random.randn(1,n1)/50;\n",
    "    X_test[:,p-1] = c_test\n",
    "    y_test = np.dot(X_test,beta) + sigma*np.random.randn(n1)\n",
    "    # Note that the matrix Z = X'X has a very small eigenvalue.\n",
    "    Z = np.dot(X_test.T,X_test)\n",
    "    np.linalg.eig(Z)[0]\n",
    "    beta_hat = np.dot(np.dot(np.linalg.inv(Z),X_test.T),y_test.T)\n",
    "    \n",
    "    for j in range(0, 5):\n",
    "        beta_hat_avg[j] = ((beta_hat_avg[j] * i) + beta_hat[j]) / (i + 1)\n",
    "\n",
    "print(beta_hat_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Alternatively, if one had access to lots of data, instead of computing the least-square solution over smaller batches and then averaging these solutions as in the previous part of the problem, an approach is to run a single least-squares regression over all the data. Which approach do you think is better? Can you support your conclusion with experiments?\n",
    "\n",
    "We have already considered an experiment above in which we run an OLS solution over 500 points 10000x. An easy way to compare would be to generate a set of 500 * 10000 = 5000000 points and compare the OLS solution we get from that data. That experiment is shown below.\n",
    "\n",
    "The difference from true beta is slightly lower with the smaller dataset averaged many times. The difference appears to be nearly an order of magnitude (error in the 0.001 range vs error in the 0.01 range) better. So the conclusion would be that it would be better to average smaller samples than it would be to run OLS on one large, complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98558886 0.97814657 1.00716553 0.99640658 0.00723274]\n"
     ]
    }
   ],
   "source": [
    "# Generate large data set equivalent to above experiment for #3 and compute beta_hat\n",
    "\n",
    "n1 = 5000000 # number of testing points\n",
    "X_test = np.random.randn(n1,p)\n",
    "# In the test set, there's more noise in the 5th column\n",
    "c_test = np.dot(X_test[:,0:p-1],[2,3,-1,0.5]) + np.random.randn(1,n1)/50;\n",
    "X_test[:,p-1] = c_test\n",
    "y_test = np.dot(X_test,beta) + sigma*np.random.randn(n1)\n",
    "# Note that the matrix Z = X'X has a very small eigenvalue.\n",
    "Z = np.dot(X_test.T,X_test)\n",
    "np.linalg.eig(Z)[0]\n",
    "beta_hat = np.dot(np.dot(np.linalg.inv(Z),X_test.T),y_test.T)\n",
    "\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
